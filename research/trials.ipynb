{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13cae57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('pip install kaggle')\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = r'C:\\\\Users\\\\aldoreni\\\\.kaggle'\n",
    "\n",
    "# Download dataset\n",
    "os.system('kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p ./data --unzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f306cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (2025.8.3)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (3.4.3)\n",
      "Requirement already satisfied: idna in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (3.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (78.1.1)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da04e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"  # directory where you uploaded kaggle.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "670e1b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\HAI\\AppData\\Local\\Temp\\ipykernel_29192\\250410435.py\", line 1, in <module>\n",
      "    import kagglehub\n",
      "ModuleNotFoundError: No module named 'kagglehub'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2170, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1457, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1348, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1195, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1110, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 992, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 804, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\stack_data\\core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\stack_data\\core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "  File \"c:\\Users\\HAI\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages\\stack_data\\core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52370cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (2025.8.3)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (3.4.3)\n",
      "Requirement already satisfied: idna in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (3.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (78.1.1)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install kaggle --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90335904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()  # current notebook directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f53f41a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
      "License(s): other\n",
      "Downloading chest-xray-pneumonia.zip to c:\\Projects\\DeepLearning\\Pneumonia_detection\\research\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/2.29G [00:00<?, ?B/s]\n",
      "  1%|          | 22.0M/2.29G [00:00<00:11, 222MB/s]\n",
      "  2%|▏         | 44.0M/2.29G [00:00<00:10, 222MB/s]\n",
      "  3%|▎         | 66.0M/2.29G [00:00<00:11, 207MB/s]\n",
      "  4%|▎         | 87.0M/2.29G [00:00<00:11, 211MB/s]\n",
      "  5%|▍         | 110M/2.29G [00:00<00:10, 218MB/s] \n",
      "  6%|▌         | 132M/2.29G [00:00<00:10, 219MB/s]\n",
      "  7%|▋         | 161M/2.29G [00:00<00:09, 245MB/s]\n",
      "  8%|▊         | 185M/2.29G [00:00<00:09, 239MB/s]\n",
      "  9%|▉         | 208M/2.29G [00:00<00:09, 226MB/s]\n",
      " 10%|█         | 236M/2.29G [00:01<00:09, 244MB/s]\n",
      " 11%|█         | 264M/2.29G [00:01<00:08, 256MB/s]\n",
      " 12%|█▏        | 289M/2.29G [00:01<00:08, 256MB/s]\n",
      " 14%|█▎        | 318M/2.29G [00:01<00:08, 262MB/s]\n",
      " 16%|█▌        | 367M/2.29G [00:01<00:06, 334MB/s]\n",
      " 17%|█▋        | 411M/2.29G [00:01<00:05, 371MB/s]\n",
      " 19%|█▉        | 450M/2.29G [00:01<00:05, 379MB/s]\n",
      " 21%|██        | 487M/2.29G [00:01<00:05, 365MB/s]\n",
      " 22%|██▏       | 523M/2.29G [00:01<00:05, 349MB/s]\n",
      " 24%|██▎       | 557M/2.29G [00:02<00:05, 335MB/s]\n",
      " 25%|██▌       | 590M/2.29G [00:02<00:05, 324MB/s]\n",
      " 26%|██▋       | 622M/2.29G [00:02<00:05, 316MB/s]\n",
      " 28%|██▊       | 653M/2.29G [00:02<00:05, 304MB/s]\n",
      " 29%|██▉       | 683M/2.29G [00:02<00:06, 277MB/s]\n",
      " 30%|███       | 710M/2.29G [00:02<00:06, 278MB/s]\n",
      " 31%|███▏      | 737M/2.29G [00:02<00:06, 272MB/s]\n",
      " 33%|███▎      | 764M/2.29G [00:02<00:06, 252MB/s]\n",
      " 34%|███▎      | 789M/2.29G [00:02<00:06, 254MB/s]\n",
      " 35%|███▍      | 814M/2.29G [00:03<00:06, 243MB/s]\n",
      " 36%|███▌      | 839M/2.29G [00:03<00:06, 248MB/s]\n",
      " 37%|███▋      | 867M/2.29G [00:03<00:05, 260MB/s]\n",
      " 38%|███▊      | 896M/2.29G [00:03<00:05, 271MB/s]\n",
      " 40%|███▉      | 929M/2.29G [00:03<00:05, 288MB/s]\n",
      " 41%|████      | 957M/2.29G [00:03<00:05, 269MB/s]\n",
      " 42%|████▏     | 988M/2.29G [00:03<00:05, 284MB/s]\n",
      " 43%|████▎     | 0.99G/2.29G [00:03<00:04, 283MB/s]\n",
      " 44%|████▍     | 1.02G/2.29G [00:03<00:04, 277MB/s]\n",
      " 46%|████▌     | 1.05G/2.29G [00:04<00:05, 262MB/s]\n",
      " 47%|████▋     | 1.07G/2.29G [00:04<00:04, 266MB/s]\n",
      " 48%|████▊     | 1.10G/2.29G [00:04<00:04, 264MB/s]\n",
      " 49%|████▉     | 1.12G/2.29G [00:04<00:04, 256MB/s]\n",
      " 50%|█████     | 1.15G/2.29G [00:04<00:04, 253MB/s]\n",
      " 51%|█████     | 1.17G/2.29G [00:04<00:04, 256MB/s]\n",
      " 52%|█████▏    | 1.20G/2.29G [00:04<00:05, 202MB/s]\n",
      " 53%|█████▎    | 1.22G/2.29G [00:04<00:05, 207MB/s]\n",
      " 54%|█████▍    | 1.24G/2.29G [00:05<00:05, 219MB/s]\n",
      " 55%|█████▌    | 1.27G/2.29G [00:05<00:04, 230MB/s]\n",
      " 56%|█████▋    | 1.29G/2.29G [00:05<00:04, 241MB/s]\n",
      " 58%|█████▊    | 1.32G/2.29G [00:05<00:04, 247MB/s]\n",
      " 59%|█████▊    | 1.34G/2.29G [00:05<00:04, 249MB/s]\n",
      " 60%|█████▉    | 1.37G/2.29G [00:05<00:03, 260MB/s]\n",
      " 61%|██████    | 1.40G/2.29G [00:05<00:03, 254MB/s]\n",
      " 62%|██████▏   | 1.42G/2.29G [00:05<00:03, 254MB/s]\n",
      " 63%|██████▎   | 1.45G/2.29G [00:05<00:03, 254MB/s]\n",
      " 64%|██████▍   | 1.48G/2.29G [00:05<00:03, 278MB/s]\n",
      " 66%|██████▌   | 1.50G/2.29G [00:06<00:03, 266MB/s]\n",
      " 67%|██████▋   | 1.53G/2.29G [00:06<00:03, 264MB/s]\n",
      " 68%|██████▊   | 1.56G/2.29G [00:06<00:02, 266MB/s]\n",
      " 69%|██████▉   | 1.58G/2.29G [00:06<00:02, 270MB/s]\n",
      " 70%|███████   | 1.61G/2.29G [00:06<00:02, 285MB/s]\n",
      " 72%|███████▏  | 1.64G/2.29G [00:06<00:02, 280MB/s]\n",
      " 73%|███████▎  | 1.67G/2.29G [00:06<00:02, 278MB/s]\n",
      " 74%|███████▍  | 1.69G/2.29G [00:06<00:02, 263MB/s]\n",
      " 75%|███████▍  | 1.72G/2.29G [00:06<00:02, 265MB/s]\n",
      " 76%|███████▌  | 1.74G/2.29G [00:07<00:02, 254MB/s]\n",
      " 79%|███████▊  | 1.80G/2.29G [00:07<00:01, 364MB/s]\n",
      " 80%|████████  | 1.84G/2.29G [00:07<00:01, 380MB/s]\n",
      " 83%|████████▎ | 1.90G/2.29G [00:07<00:00, 446MB/s]\n",
      " 86%|████████▌ | 1.96G/2.29G [00:07<00:00, 508MB/s]\n",
      " 88%|████████▊ | 2.03G/2.29G [00:07<00:00, 560MB/s]\n",
      " 91%|█████████▏| 2.09G/2.29G [00:07<00:00, 601MB/s]\n",
      " 94%|█████████▍| 2.16G/2.29G [00:07<00:00, 624MB/s]\n",
      " 97%|█████████▋| 2.23G/2.29G [00:07<00:00, 643MB/s]\n",
      "100%|██████████| 2.29G/2.29G [00:07<00:00, 310MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a9d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (2025.8.3)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (3.4.3)\n",
      "Requirement already satisfied: idna in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (3.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (78.1.1)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hai\\anaconda3\\envs\\deeplearning_mlop\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install kaggle --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78656ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                               title                                                   size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
      "----------------------------------------------------------------  ------------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
      "yashdevladdha/uber-ride-analytics-dashboard                       Uber Data Analytics Dashboard                       17324552  2025-08-08 11:13:42                 48312       1069  1.0              \n",
      "mosapabdelghany/medical-insurance-cost-dataset                    Medical Insurance Cost Dataset                         16425  2025-08-24 11:54:36.533000           2915         72  1.0              \n",
      "zadafiyabhrami/global-crocodile-species-dataset                   Global Crocodile Species Dataset                       57473  2025-08-26 08:46:11                  2326         75  1.0              \n",
      "codebynadiia/gdp-per-country-20202025                             GDP per Country 2020–2025                               5677  2025-09-04 14:37:43.563000           1833         45  1.0              \n",
      "msnbehdani/mock-dataset-of-second-hand-car-sales                  Car Sales Dataset: Model, Features, and Pricing       501188  2025-08-20 17:47:58.207000           4111         67  1.0              \n",
      "eshummalik/bmw-sales-dataset                                      BMW_Sales_Dataset                                     853348  2025-09-05 08:28:34                  1819         45  1.0              \n",
      "zubairamuti/shopping-behaviours-dataset                           Shopping behaviours dataset                            72157  2025-08-29 14:56:21.637000           2017         38  1.0              \n",
      "mdsultanulislamovi/student-stress-monitoring-datasets             Student Stress Monitoring Datasets                     24336  2025-07-24 16:30:01.617000          26711        439  1.0              \n",
      "mirzayasirabdullah07/student-exam-scores-dataset                  Student Exam Scores dataset                             2430  2025-08-20 07:26:47.233000           2263         37  0.88235295       \n",
      "ikramshah512/amazon-products-sales-dataset-42k-items-2025         Amazon Products Sales Dataset 42K+ Items - 2025      8086390  2025-09-01 02:31:27.053000           2847         48  1.0              \n",
      "snehabhat23/top-rated-movies                                      MOVIES DATASET (tmdb)                                1273623  2025-09-04 11:35:53                   922         23  1.0              \n",
      "poushal02/student-academic-stress-real-world-dataset              Student Academic Stress Real World Dataset              2104  2025-08-20 07:49:12                  6506        132  1.0              \n",
      "mikeytracegod/lung-cancer-risk-dataset                            Lung-Cancer-Risk-Dataset                              888060  2025-08-23 10:04:14                  1490         27  1.0              \n",
      "imaadmahmood/global-finance-and-economic-indicators-dataset-2024  Financial Market Datasets 2024                          2795  2025-08-17 20:56:29                  1489         25  0.8235294        \n",
      "shivamshinde1904/weather-data2000-2023                            Weather Data(2000-2023)                             11285005  2025-09-08 08:40:00.557000            713         22  1.0              \n",
      "julianbloise/winners-formula-1-1950-to-2025                       Formula 1 Grand Prix Winners Dataset (1950–2025)       17788  2025-08-27 17:37:48.427000           1486         26  1.0              \n",
      "arnabnahaushna/imdb-top-250-movies-of-all-time                    IMDB - Top 250 Movies of All Time                      19974  2025-08-25 17:04:40                  1342         32  1.0              \n",
      "rohitgrewal/hr-data-mnc                                           HR Dataset (Multinational Company)                  69930946  2025-08-23 06:53:08                  2358         55  1.0              \n",
      "rohitgrewal/airlines-flights-data                                 Airlines Flights Data                                2440299  2025-07-29 09:16:00.463000          26644        451  1.0              \n",
      "ayushghawana/perfume-dataset                                      Perfume Dataset                                        10691  2025-09-02 18:02:08.533000           1272         30  1.0              \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5902b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e0d0bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = \"chest-xray-pneumonia.zip\"   # your downloaded ZIP\n",
    "target_path = r\"C:\\Projects\\DeepLearning\\Pneumonia_detection\\data\"  # target folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17dba9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(target_path, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(target_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning_mlop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
